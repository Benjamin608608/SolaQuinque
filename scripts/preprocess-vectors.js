#!/usr/bin/env node

/**
 * å‘é‡è³‡æ–™é è™•ç†è…³æœ¬
 * 
 * æ­¤è…³æœ¬å°‡ï¼š
 * 1. å¾ Google Drive ä¸‹è¼‰æ‰€æœ‰æ–‡æœ¬æ–‡ä»¶
 * 2. å°‡æ–‡æœ¬åˆ†å‰²æˆèªç¾©ç‰‡æ®µ
 * 3. ç”Ÿæˆ OpenAI embeddings
 * 4. ä¿å­˜ç‚ºç·Šæ¹Šçš„å‘é‡è³‡æ–™æ–‡ä»¶
 * 5. å¯é¸ï¼šä¸Šå‚³è™•ç†å¾Œçš„å‘é‡è³‡æ–™åˆ° Google Drive
 * 
 * ä½¿ç”¨æ–¹æ³•ï¼š
 * node scripts/preprocess-vectors.js
 * 
 * ç’°å¢ƒè®Šæ•¸ï¼š
 * - OPENAI_API_KEY: OpenAI API å¯†é‘°
 * - GOOGLE_DRIVE_API_KEY: Google Drive API å¯†é‘°
 * - GOOGLE_DRIVE_FOLDER_ID: æºæ–‡ä»¶è³‡æ–™å¤¾ ID
 */

require('dotenv').config();
const fs = require('fs').promises;
const path = require('path');
const OpenAI = require('openai');
const fetch = require('node-fetch');

class VectorPreprocessor {
    constructor() {
        this.openai = new OpenAI({
            apiKey: process.env.OPENAI_API_KEY
        });
        
        this.googleDriveApiKey = process.env.GOOGLE_DRIVE_API_KEY;
        this.sourceFolderId = process.env.GOOGLE_DRIVE_FOLDER_ID || '1e9Gup33c5nPaM6zRi8bQxI0kqWfUcc2K';
        
        this.outputDir = path.join(__dirname, '../data/preprocessed');
        this.tempDir = path.join(__dirname, '../data/temp');
        
        // å‘é‡è³‡æ–™çµæ§‹
        this.vectorData = {
            version: '1.0.0',
            createdAt: new Date().toISOString(),
            model: 'text-embedding-3-small',
            dimensions: 1536,
            totalFiles: 0,
            totalChunks: 0,
            chunks: []  // { text, source, embedding, metadata }
        };
    }
    
    async initialize() {
        console.log('ğŸš€ åˆå§‹åŒ–å‘é‡è³‡æ–™é è™•ç†å™¨...');
        
        // æª¢æŸ¥å¿…è¦çš„ç’°å¢ƒè®Šæ•¸
        if (!process.env.OPENAI_API_KEY) {
            throw new Error('âŒ ç¼ºå°‘ OPENAI_API_KEY ç’°å¢ƒè®Šæ•¸');
        }
        
        if (!this.googleDriveApiKey) {
            throw new Error('âŒ ç¼ºå°‘ GOOGLE_DRIVE_API_KEY ç’°å¢ƒè®Šæ•¸');
        }
        
        // å‰µå»ºå¿…è¦çš„ç›®éŒ„
        await fs.mkdir(this.outputDir, { recursive: true });
        await fs.mkdir(this.tempDir, { recursive: true });
        
        console.log('âœ… é è™•ç†å™¨åˆå§‹åŒ–å®Œæˆ');
        console.log(`ğŸ“ è¼¸å‡ºç›®éŒ„: ${this.outputDir}`);
        console.log(`ğŸ“ è‡¨æ™‚ç›®éŒ„: ${this.tempDir}`);
    }
    
    // åˆ—å‡º Google Drive è³‡æ–™å¤¾ä¸­çš„æ‰€æœ‰æ–‡ä»¶
    async listGoogleDriveFiles(folderId) {
        console.log(`ğŸ“‹ åˆ—å‡º Google Drive è³‡æ–™å¤¾ä¸­çš„æ–‡ä»¶: ${folderId}`);
        
        let allFiles = [];
        let pageToken = null;
        let pageCount = 0;
        
        do {
            pageCount++;
            console.log(`ğŸ“„ ç²å–ç¬¬ ${pageCount} é æ–‡ä»¶...`);
            
            let apiUrl = `https://www.googleapis.com/drive/v3/files?q='${folderId}'+in+parents&fields=files(id,name,mimeType,size),nextPageToken&pageSize=1000&key=${this.googleDriveApiKey}`;
            if (pageToken) {
                apiUrl += `&pageToken=${pageToken}`;
            }
            
            const response = await fetch(apiUrl);
            if (!response.ok) {
                throw new Error(`Google Drive API è«‹æ±‚å¤±æ•—: ${response.status} ${response.statusText}`);
            }
            
            const data = await response.json();
            const files = data.files || [];
            
            console.log(`âœ… ç¬¬ ${pageCount} é ç²å–åˆ° ${files.length} å€‹æ–‡ä»¶`);
            allFiles.push(...files);
            pageToken = data.nextPageToken;
            
            if (pageToken) {
                console.log(`ğŸ”„ ç™¼ç¾æ›´å¤šæ–‡ä»¶ï¼Œæº–å‚™ç²å–ä¸‹ä¸€é ...`);
                await new Promise(resolve => setTimeout(resolve, 1000));
            }
        } while (pageToken);
        
        // éæ¿¾å‡º .txt æ–‡ä»¶
        const textFiles = allFiles.filter(file => 
            file.name.toLowerCase().endsWith('.txt') && 
            file.mimeType === 'text/plain'
        );
        
        console.log(`ğŸ‰ ç¸½å…±ç²å–åˆ° ${allFiles.length} å€‹æ–‡ä»¶ï¼Œå…¶ä¸­ ${textFiles.length} å€‹ .txt æ–‡ä»¶`);
        return textFiles;
    }
    
    // ä¸‹è¼‰å–®å€‹æ–‡ä»¶
    async downloadFile(fileId, fileName, outputPath) {
        console.log(`ğŸ“¥ ä¸‹è¼‰æ–‡ä»¶: ${fileName}`);
        
        const downloadUrl = `https://drive.usercontent.google.com/download?id=${fileId}&export=download&confirm=t`;
        
        const response = await fetch(downloadUrl, {
            headers: {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
        });
        
        if (!response.ok) {
            throw new Error(`ä¸‹è¼‰å¤±æ•—: ${response.status} ${response.statusText}`);
        }
        
        const fileStream = require('fs').createWriteStream(outputPath);
        response.body.pipe(fileStream);
        
        return new Promise((resolve, reject) => {
            fileStream.on('finish', resolve);
            fileStream.on('error', reject);
        });
    }
    
    // å°‡æ–‡æœ¬åˆ†å‰²æˆèªç¾©ç‰‡æ®µ
    splitTextIntoChunks(text, fileName) {
        const chunkSize = 1500;  // é«˜å“è³ªè¨­å®š
        const overlap = 200;
        const chunks = [];
        
        // æŒ‰æ®µè½åˆ†å‰²
        const paragraphs = text.split(/\n\s*\n/).filter(p => p.trim().length > 0);
        
        let currentChunk = '';
        let chunkIndex = 0;
        
        for (const paragraph of paragraphs) {
            const trimmedParagraph = paragraph.trim();
            
            // è·³éå¤ªçŸ­çš„æ®µè½
            if (trimmedParagraph.length < 100) continue;
            
            if (currentChunk.length + trimmedParagraph.length > chunkSize && currentChunk.length > 0) {
                // ä¿å­˜ç•¶å‰ç‰‡æ®µ
                chunks.push({
                    text: currentChunk.trim(),
                    source: fileName,
                    chunkIndex: chunkIndex++,
                    metadata: {
                        length: currentChunk.length,
                        wordCount: currentChunk.split(/\s+/).length
                    }
                });
                
                // é–‹å§‹æ–°ç‰‡æ®µï¼Œä¿ç•™é‡ç–Šéƒ¨åˆ†
                const words = currentChunk.split(/\s+/);
                const overlapWords = words.slice(-Math.floor(overlap / 5)); // å¤§ç´„ overlap å­—ç¬¦çš„è©æ•¸
                currentChunk = overlapWords.join(' ') + ' ' + trimmedParagraph;
            } else {
                currentChunk += (currentChunk ? '\n\n' : '') + trimmedParagraph;
            }
        }
        
        // ä¿å­˜æœ€å¾Œä¸€å€‹ç‰‡æ®µ
        if (currentChunk.trim().length > 100) {
            chunks.push({
                text: currentChunk.trim(),
                source: fileName,
                chunkIndex: chunkIndex,
                metadata: {
                    length: currentChunk.length,
                    wordCount: currentChunk.split(/\s+/).length
                }
            });
        }
        
        return chunks;
    }
    
    // ç”ŸæˆåµŒå…¥å‘é‡
    async generateEmbedding(text) {
        try {
            const response = await this.openai.embeddings.create({
                model: 'text-embedding-3-small',
                input: text,
                dimensions: 1536
            });
            
            return Array.from(response.data[0].embedding);
        } catch (error) {
            console.error('âŒ ç”ŸæˆåµŒå…¥å‘é‡å¤±æ•—:', error.message);
            // è¿”å›é›¶å‘é‡ä½œç‚ºå¾Œå‚™
            return new Array(1536).fill(0);
        }
    }
    
    // æ‰¹é‡ç”ŸæˆåµŒå…¥å‘é‡
    async generateEmbeddings(chunks) {
        console.log(`ğŸ”„ é–‹å§‹ç”Ÿæˆ ${chunks.length} å€‹åµŒå…¥å‘é‡...`);
        
        const BATCH_SIZE = 50;
        const PROGRESS_INTERVAL = 100;
        let processedCount = 0;
        
        for (let i = 0; i < chunks.length; i += BATCH_SIZE) {
            const batch = chunks.slice(i, i + BATCH_SIZE);
            const batchNum = Math.floor(i / BATCH_SIZE) + 1;
            const totalBatches = Math.ceil(chunks.length / BATCH_SIZE);
            
            console.log(`ğŸ“¦ è™•ç†åµŒå…¥å‘é‡æ‰¹æ¬¡ ${batchNum}/${totalBatches} (${batch.length} å€‹ç‰‡æ®µ)`);
            
            try {
                const batchPromises = batch.map(async (chunk) => {
                    const embedding = await this.generateEmbedding(chunk.text);
                    return { ...chunk, embedding };
                });
                
                const batchResults = await Promise.all(batchPromises);
                
                // æ·»åŠ åˆ°ä¸»è³‡æ–™çµæ§‹
                this.vectorData.chunks.push(...batchResults);
                
                processedCount += batch.length;
                
                if (processedCount % PROGRESS_INTERVAL === 0 || batchNum === totalBatches) {
                    const progress = ((processedCount / chunks.length) * 100).toFixed(1);
                    console.log(`ğŸ“ˆ åµŒå…¥å‘é‡é€²åº¦: ${progress}% (${processedCount}/${chunks.length})`);
                }
                
                // API é™åˆ¶ï¼šæ¯åˆ†é˜æœ€å¤š 3000 requests
                if (i + BATCH_SIZE < chunks.length) {
                    await new Promise(resolve => setTimeout(resolve, 1000));
                }
                
            } catch (error) {
                console.error(`âŒ æ‰¹æ¬¡ ${batchNum} è™•ç†å¤±æ•—:`, error.message);
                // æ·»åŠ é›¶å‘é‡ä½œç‚ºå¾Œå‚™
                const fallbackResults = batch.map(chunk => ({
                    ...chunk,
                    embedding: new Array(1536).fill(0)
                }));
                this.vectorData.chunks.push(...fallbackResults);
                processedCount += batch.length;
            }
        }
        
        console.log(`âœ… æˆåŠŸç”Ÿæˆ ${this.vectorData.chunks.length} å€‹åµŒå…¥å‘é‡`);
    }
    
    // è™•ç†æ‰€æœ‰æ–‡ä»¶
    async processAllFiles() {
        console.log('ğŸ“‹ é–‹å§‹è™•ç†æ‰€æœ‰æ–‡ä»¶...');
        
        // 1. åˆ—å‡ºæ‰€æœ‰æ–‡ä»¶
        const files = await this.listGoogleDriveFiles(this.sourceFolderId);
        this.vectorData.totalFiles = files.length;
        
        if (files.length === 0) {
            throw new Error('âŒ æ²’æœ‰æ‰¾åˆ°ä»»ä½• .txt æ–‡ä»¶');
        }
        
        // 2. ä¸‹è¼‰ä¸¦è™•ç†æ–‡ä»¶
        let allChunks = [];
        let processedFiles = 0;
        
        console.log(`ğŸ”„ é–‹å§‹è™•ç† ${files.length} å€‹æ–‡ä»¶...`);
        
        for (const file of files) {
            try {
                processedFiles++;
                console.log(`\nğŸ“ è™•ç†æ–‡ä»¶ ${processedFiles}/${files.length}: ${file.name}`);
                
                // ä¸‹è¼‰æ–‡ä»¶
                const tempFilePath = path.join(this.tempDir, file.name);
                await this.downloadFile(file.id, file.name, tempFilePath);
                
                // è®€å–æ–‡ä»¶å…§å®¹
                const content = await fs.readFile(tempFilePath, 'utf-8');
                
                // åˆ†å‰²æˆç‰‡æ®µ
                const chunks = this.splitTextIntoChunks(content, file.name);
                console.log(`ğŸ“š æå–äº† ${chunks.length} å€‹æ–‡æœ¬ç‰‡æ®µ`);
                
                allChunks.push(...chunks);
                
                // æ¸…ç†è‡¨æ™‚æ–‡ä»¶
                await fs.unlink(tempFilePath);
                
                // é€²åº¦å ±å‘Š
                if (processedFiles % 10 === 0) {
                    console.log(`ğŸ“Š å·²è™•ç† ${processedFiles}/${files.length} å€‹æ–‡ä»¶ï¼Œç´¯è¨ˆ ${allChunks.length} å€‹ç‰‡æ®µ`);
                }
                
            } catch (error) {
                console.error(`âŒ è™•ç†æ–‡ä»¶ ${file.name} å¤±æ•—:`, error.message);
                continue;
            }
        }
        
        this.vectorData.totalChunks = allChunks.length;
        console.log(`\nğŸ‰ æ–‡ä»¶è™•ç†å®Œæˆï¼`);
        console.log(`ğŸ“Š è™•ç†äº† ${processedFiles} å€‹æ–‡ä»¶ï¼Œæå–äº† ${allChunks.length} å€‹æ–‡æœ¬ç‰‡æ®µ`);
        
        // 3. ç”ŸæˆåµŒå…¥å‘é‡
        await this.generateEmbeddings(allChunks);
    }
    
    // ä¿å­˜å‘é‡è³‡æ–™
    async saveVectorData() {
        const outputFile = path.join(this.outputDir, 'theology-vectors.json');
        const compressedFile = path.join(this.outputDir, 'theology-vectors-compressed.json');
        
        console.log('ğŸ’¾ ä¿å­˜å‘é‡è³‡æ–™...');
        
        // ä¿å­˜å®Œæ•´ç‰ˆæœ¬ï¼ˆç”¨æ–¼èª¿è©¦ï¼‰
        await fs.writeFile(outputFile, JSON.stringify(this.vectorData, null, 2));
        console.log(`âœ… å®Œæ•´å‘é‡è³‡æ–™å·²ä¿å­˜: ${outputFile}`);
        
        // ä¿å­˜å£“ç¸®ç‰ˆæœ¬ï¼ˆç”¨æ–¼ç”Ÿç”¢ï¼‰
        await fs.writeFile(compressedFile, JSON.stringify(this.vectorData));
        console.log(`âœ… å£“ç¸®å‘é‡è³‡æ–™å·²ä¿å­˜: ${compressedFile}`);
        
        // é¡¯ç¤ºæ–‡ä»¶å¤§å°
        const stats = await fs.stat(compressedFile);
        const sizeMB = (stats.size / 1024 / 1024).toFixed(2);
        console.log(`ğŸ“Š å£“ç¸®æ–‡ä»¶å¤§å°: ${sizeMB} MB`);
        
        return compressedFile;
    }
    
    // ç”Ÿæˆçµ±è¨ˆå ±å‘Š
    generateReport() {
        const report = {
            summary: {
                totalFiles: this.vectorData.totalFiles,
                totalChunks: this.vectorData.totalChunks,
                avgChunksPerFile: (this.vectorData.totalChunks / this.vectorData.totalFiles).toFixed(1),
                model: this.vectorData.model,
                dimensions: this.vectorData.dimensions
            },
            fileStats: {},
            chunkStats: {
                avgLength: 0,
                avgWordCount: 0,
                minLength: Infinity,
                maxLength: 0
            }
        };
        
        // è¨ˆç®—æ–‡ä»¶çµ±è¨ˆ
        for (const chunk of this.vectorData.chunks) {
            if (!report.fileStats[chunk.source]) {
                report.fileStats[chunk.source] = 0;
            }
            report.fileStats[chunk.source]++;
            
            // ç‰‡æ®µçµ±è¨ˆ
            const length = chunk.metadata.length;
            const wordCount = chunk.metadata.wordCount;
            
            report.chunkStats.avgLength += length;
            report.chunkStats.avgWordCount += wordCount;
            report.chunkStats.minLength = Math.min(report.chunkStats.minLength, length);
            report.chunkStats.maxLength = Math.max(report.chunkStats.maxLength, length);
        }
        
        report.chunkStats.avgLength = Math.round(report.chunkStats.avgLength / this.vectorData.totalChunks);
        report.chunkStats.avgWordCount = Math.round(report.chunkStats.avgWordCount / this.vectorData.totalChunks);
        
        return report;
    }
}

// ä¸»åŸ·è¡Œå‡½æ•¸
async function main() {
    const preprocessor = new VectorPreprocessor();
    
    try {
        console.log('ğŸš€ é–‹å§‹å‘é‡è³‡æ–™é è™•ç†...\n');
        
        // åˆå§‹åŒ–
        await preprocessor.initialize();
        
        // è™•ç†æ‰€æœ‰æ–‡ä»¶
        await preprocessor.processAllFiles();
        
        // ä¿å­˜çµæœ
        const outputFile = await preprocessor.saveVectorData();
        
        // ç”Ÿæˆå ±å‘Š
        const report = preprocessor.generateReport();
        console.log('\nğŸ“Š è™•ç†å ±å‘Š:');
        console.log(JSON.stringify(report, null, 2));
        
        // ä¿å­˜å ±å‘Š
        const reportFile = path.join(preprocessor.outputDir, 'processing-report.json');
        await fs.writeFile(reportFile, JSON.stringify(report, null, 2));
        console.log(`ğŸ“‹ è™•ç†å ±å‘Šå·²ä¿å­˜: ${reportFile}`);
        
        console.log('\nğŸ‰ å‘é‡è³‡æ–™é è™•ç†å®Œæˆï¼');
        console.log(`ğŸ“ è¼¸å‡ºæ–‡ä»¶: ${outputFile}`);
        console.log('\nğŸ’¡ ä¸‹ä¸€æ­¥ï¼š');
        console.log('1. å°‡ theology-vectors-compressed.json ä¸Šå‚³åˆ° Google Drive');
        console.log('2. æ›´æ–° Railway æ‡‰ç”¨ä»¥è¼‰å…¥é è™•ç†çš„å‘é‡è³‡æ–™');
        console.log('3. äº«å—å¿«é€Ÿçš„å•Ÿå‹•æ™‚é–“ï¼ğŸš€');
        
    } catch (error) {
        console.error('\nâŒ é è™•ç†å¤±æ•—:', error.message);
        console.error(error.stack);
        process.exit(1);
    }
}

// å¦‚æœç›´æ¥åŸ·è¡Œæ­¤è…³æœ¬
if (require.main === module) {
    main();
}

module.exports = VectorPreprocessor;